{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import cPickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import svgwrite # conda install -c omnia svgwrite=1.1.6\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from svgpathtools import svg2paths, wsvg\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)\n",
    "\n",
    "from magenta.models.sketch_rnn.sketch_rnn_train import *\n",
    "from magenta.models.sketch_rnn.model import *\n",
    "from magenta.models.sketch_rnn.utils import *\n",
    "from magenta.models.sketch_rnn.rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"TensorFlow Version: %s\", tf.__version__)\n",
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=0.2, svg_filename = 'home/calpeyser/sketch/svg/sample.svg'):\n",
    "  tf.gfile.MakeDirs(os.path.dirname(svg_filename))\n",
    "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "  lift_pen = 1\n",
    "  abs_x = 25 - min_x \n",
    "  abs_y = 25 - min_y\n",
    "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "  command = \"m\"\n",
    "  for i in xrange(len(data)):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"black\"\n",
    "  stroke_width = 1\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  dwg.save()\n",
    "  #display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
    "  def get_start_and_end(x):\n",
    "    x = np.array(x)\n",
    "    x = x[:, 0:2]\n",
    "    x_start = x[0]\n",
    "    x_end = x.sum(axis=0)\n",
    "    x = x.cumsum(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x_min = x.min(axis=0)\n",
    "    center_loc = (x_max+x_min)*0.5\n",
    "    return x_start-center_loc, x_end\n",
    "  x_pos = 0.0\n",
    "  y_pos = 0.0\n",
    "  result = [[x_pos, y_pos, 1]]\n",
    "  for sample in s_list:\n",
    "    s = sample[0]\n",
    "    grid_loc = sample[1]\n",
    "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "    start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "    loc_x = start_loc[0]\n",
    "    loc_y = start_loc[1]\n",
    "    new_x_pos = grid_x+loc_x\n",
    "    new_y_pos = grid_y+loc_y\n",
    "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "    result += s.tolist()\n",
    "    result[-1][2] = 1\n",
    "    x_pos = new_x_pos+delta_pos[0]\n",
    "    y_pos = new_y_pos+delta_pos[1]\n",
    "  return np.array(result)\n",
    "\n",
    "sheep_model_dir = \"/home/calpeyser/sketch/models/aaron_sheep/lstm\"\n",
    "sheep_data_dir = \"http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/\"\n",
    "owl_model_dir = \"/home/calpeyser/sketch/models/owl/lstm\"\n",
    "owl_data_dir = \"/home/calpeyser/sketch/data/owl/\"\n",
    "flam_model_dir = \"/home/calpeyser/sketch/models/flamingo/lstm_uncond\"\n",
    "flam_data_dir = \"/home/calpeyser/sketch/data/flamingo/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Downloading http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/aaron_sheep.npz\n",
      "INFO:tensorflow:Loaded 7400/300/300 from aaron_sheep.npz\n",
      "INFO:tensorflow:Dataset combined: 8000 (7400/300/300), avg len 125\n",
      "INFO:tensorflow:model_params.max_seq_len 250.\n",
      "total images <= max_seq_len is 7400\n",
      "total images <= max_seq_len is 300\n",
      "total images <= max_seq_len is 300\n",
      "INFO:tensorflow:normalizing_scale_factor 18.5198.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n",
      "INFO:tensorflow:Loaded 70000/2500/2500 from extended_owl.npz\n",
      "INFO:tensorflow:Dataset combined: 75000 (70000/2500/2500), avg len 85\n",
      "INFO:tensorflow:model_params.max_seq_len 148.\n",
      "total images <= max_seq_len is 70000\n",
      "total images <= max_seq_len is 2500\n",
      "total images <= max_seq_len is 2500\n",
      "INFO:tensorflow:normalizing_scale_factor 42.7029.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n"
     ]
    }
   ],
   "source": [
    "[sheep_train_set, sheep_valid_set, sheep_test_set, sheep_hps_model, sheep_eval_hps_model, sheep_sample_hps_model] = load_env(sheep_data_dir, sheep_model_dir)\n",
    "sheep_eval_model = Model(sheep_eval_hps_model, reuse=False)\n",
    "sheep_sample_model = Model(sheep_sample_hps_model, reuse=True)\n",
    "\n",
    "[owl_train_set, owl_valid_set, owl_test_set, owl_hps_model, owl_eval_hps_model, owl_sample_hps_model] = load_env(owl_data_dir, owl_model_dir)\n",
    "owl_eval_model = Model(owl_eval_hps_model, reuse=True)\n",
    "owl_sample_model = Model(owl_sample_hps_model, reuse=True)\n",
    "\n",
    "\n",
    "#[flam_train_set, flam_valid_set, flam_test_set, flam_hps_model, flam_eval_hps_model, flam_sample_hps_model] = load_env(flam_data_dir, flam_model_dir)\n",
    "#flam_eval_model = Model(flam_eval_hps_model, reuse=True)\n",
    "#flam_sample_model = Model(flam_sample_hps_model, reuse=True)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(eval_model, input_strokes, max_len=129):\n",
    "  strokes = to_big_strokes(input_strokes, max_len=max_len).tolist()\n",
    "  strokes.insert(0, [0, 0, 1, 0, 0])\n",
    "  seq_len = [len(input_strokes)]\n",
    "  #draw_strokes(to_normal_strokes(np.array(strokes)))\n",
    "  return sess.run(eval_model.batch_z, feed_dict={eval_model.input_data: [strokes], eval_model.sequence_lengths: seq_len})[0]\n",
    "def decode(eval_model, sample_model, z_input=None, draw_mode=True, temperature=0.1, factor=0.2):\n",
    "  z = None\n",
    "  if z_input is not None:\n",
    "    z = [z_input]\n",
    "  sample_strokes, m = sample(sess, sample_model, seq_len=eval_model.hps.max_seq_len, temperature=temperature, z=z)\n",
    "  strokes = to_normal_strokes(sample_strokes)\n",
    "  return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint(sess, cat_model_dir)\n",
    "cat = cat_test_set.random_sample()\n",
    "print(cat.shape)\n",
    "encoding = encode(cat_eval_model, cat)\n",
    "decoding = decode(cat_eval_model, cat_sample_model, encoding)\n",
    "\n",
    "draw_strokes(cat)\n",
    "print(encoding)\n",
    "draw_strokes(decoding)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "for i in range(1000):\n",
    "    draw_strokes(owl_train_set.strokes[i], svg_filename=\"/home/calpeyser/sketch/sketches/owl/\" + str(i) + \".svg\")\n",
    "    if (i % 100 == 0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort samples by size\n",
    "def svg_len(paths):\n",
    "    out = 0\n",
    "    for line in paths:\n",
    "        out += line.length()\n",
    "    return out\n",
    "\n",
    "def sort_category(category):\n",
    "    sorted_svgs = []\n",
    "    for i in range(1000):\n",
    "        paths, attributes = svg2paths('/home/calpeyser/sketch/sketches/' + category + '/' + str(i) + '.svg')\n",
    "        sorted_svgs.append((i, svg_len(paths)))\n",
    "    sorted_svgs = sorted(sorted_svgs, key=lambda tup:tup[1])\n",
    "    return [sorted_svgs[i][0] for i in range(1000)]\n",
    "\n",
    "sheep_by_size_ind = sort_category(\"sheep\")\n",
    "owl_by_size_ind = sort_category(\"owl\")\n",
    "\n",
    "# load sheep model, map sketches onto embeddings\n",
    "load_checkpoint(sess, sheep_model_dir)\n",
    "sheep_by_size = [encode(sheep_eval_model, sheep_train_set.strokes[i], max_len=250) for i in sheep_by_size_ind]\n",
    "\n",
    "\n",
    "# load owl model, map sketches onto embeddings\n",
    "load_checkpoint(sess, owl_model_dir)\n",
    "owl_by_size = [encode(owl_eval_model, owl_train_set.strokes[i], max_len=148) for i in owl_by_size_ind]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pkl\n",
    "PKL_path = '/home/calpeyser/sketch/labels/'\n",
    "f = open(PKL_path + 'sheep', 'wb')\n",
    "pickle.dump(sheep_by_size, f)\n",
    "f.close()\n",
    "\n",
    "f = open(PKL_path + 'sheep_ind', 'wb')\n",
    "pickle.dump(sheep_by_size_ind, f)\n",
    "f.close()\n",
    "\n",
    "f = open(PKL_path + 'owl', 'wb')\n",
    "pickle.dump(owl_by_size, f)\n",
    "f.close()\n",
    "\n",
    "f = open(PKL_path + 'owl_ind', 'wb')\n",
    "pickle.dump(owl_by_size_ind, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pkl\n",
    "PKL_path = '/home/calpeyser/sketch/labels/'\n",
    "sheep_by_size = pickle.load(open('/home/calpeyser/sketch/labels/sheep', 'rb'))\n",
    "sheep_by_size_ind = pickle.load(open('/home/calpeyser/sketch/labels/sheep_ind', 'rb')) \n",
    "owl_by_size = pickle.load(open('/home/calpeyser/sketch/labels/owl', 'rb'))\n",
    "owl_by_size_ind = pickle.load(open('/home/calpeyser/sketch/labels/owl_ind', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model /home/calpeyser/sketch/models/aaron_sheep/lstm/vector.\n",
      "INFO:tensorflow:Restoring parameters from /home/calpeyser/sketch/models/aaron_sheep/lstm/vector\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5857c8e4dced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheep_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheep_by_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdecoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheep_eval_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheep_sample_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msheep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mreal_sheep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheep_train_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrokes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msheep_by_size_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-67d3c4f1147d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(eval_model, sample_model, z_input, draw_mode, temperature, factor)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mz_input\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mz_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0msample_strokes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mstrokes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_normal_strokes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_strokes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstrokes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/sketch_rnn/model.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(sess, model, seq_len, temperature, greedy_mode, z)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     ], feed)\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mo_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_mu1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_mu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_sigma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_sigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_pen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Sanity check encodings\n",
    "sheep = []\n",
    "real_sheep = []\n",
    "owl = []\n",
    "real_owl = []\n",
    "\n",
    "# Decode sheep\n",
    "load_checkpoint(sess, sheep_model_dir)\n",
    "for i, s in enumerate(sheep_by_size[:10]):\n",
    "    decoding = decode(sheep_eval_model, sheep_sample_model, s)\n",
    "    sheep.append(decoding)\n",
    "    real_sheep.append(sheep_train_set.strokes[sheep_by_size_ind[i]])\n",
    "    \n",
    "# Decode owls\n",
    "load_checkpoint(sess, owl_model_dir)\n",
    "for i, o in enumerate(owl_by_size[:10]):\n",
    "    decoding = decode(owl_eval_model, owl_sample_model, o)\n",
    "    owl.append(decoding)\n",
    "    real_owl.append(owl_train_set.strokes[owl_by_size_ind[i]])\n",
    "    \n",
    "for d, s, r, o in zip(real_sheep, sheep, real_owl, owl):\n",
    "    draw_strokes(d)\n",
    "    draw_strokes(s)\n",
    "    draw_strokes(r)\n",
    "    draw_strokes(o)\n",
    "    print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average variance across data\n",
    "sheep_variences = np.var(np.array(sheep_by_size), axis=0)\n",
    "owl_variences = np.var(np.array(owl_by_size), axis=0)\n",
    "variances = np.mean([sheep_variences, owl_variences], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cost: 3.6913576126098633 \n",
      "Epoch: 1000, Cost: 2.1215845024585724 \n",
      "Epoch: 2000, Cost: 1.6967456859350205 \n",
      "Epoch: 3000, Cost: 1.6719927481412888 \n",
      "Epoch: 4000, Cost: 1.665764701128006 \n",
      "Epoch: 5000, Cost: 1.6667826129198073 \n",
      "Epoch: 6000, Cost: 1.6591135046482086 \n",
      "Epoch: 7000, Cost: 1.664141592144966 \n",
      "Epoch: 8000, Cost: 1.6608772985935212 \n",
      "Epoch: 9000, Cost: 1.6705185542106629 \n",
      "Epoch: 10000, Cost: 1.668468116402626 \n",
      "Epoch: 11000, Cost: 1.671422826886177 \n",
      "Epoch: 12000, Cost: 1.669967038989067 \n",
      "Epoch: 13000, Cost: 1.6693645145893097 \n",
      "Epoch: 14000, Cost: 1.665159479856491 \n"
     ]
    }
   ],
   "source": [
    "# Train a linear model on the sketch labels\n",
    "STARTER_LEARNING_RATE = 0.04\n",
    "EPOCH_COUNT = 15000\n",
    "\n",
    "linear_graph = tf.Graph()\n",
    "with linear_graph.as_default():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(STARTER_LEARNING_RATE, global_step, 10000, 0.96, staircase=True)\n",
    "\n",
    "    # Constants: MSE weights\n",
    "    VAR_x_to_y = tf.constant(variances)\n",
    "\n",
    "    # TF graph input\n",
    "    X = tf.placeholder(\"float64\")\n",
    "    Y = tf.placeholder(\"float64\")\n",
    "\n",
    "    # TF weights\n",
    "    #W = tf.Variable(np.random.rand(128, 128), name = \"linear_model_weight\")\n",
    "    W_x_to_y = tf.Variable(np.random.rand(128), name = \"linear_model_weight_x_to_y\")\n",
    "    b_x_to_y = tf.Variable(np.random.rand(128), name = \"linear_model_bias_x_to_y\")\n",
    "    W_y_to_x = tf.Variable(np.random.rand(128), name = \"linear_model_weight_y_to_x\")\n",
    "    b_y_to_x = tf.Variable(np.random.rand(128), name = \"linear_model_weight_y_to_x\")\n",
    "\n",
    "    # Linear prediction\n",
    "    #prediction = tf.squeeze(tf.add(tf.matmul(tf.expand_dims(X, 0), W), b))\n",
    "    prediction_x_to_y = tf.add(tf.multiply(X, W_x_to_y), b_x_to_y)\n",
    "    prediction_y_to_x = tf.add(tf.multiply(Y, W_y_to_x), b_y_to_x)\n",
    "    \n",
    "    \n",
    "    #cost = tf.reduce_sum(tf.pow(prediction - Y, 2)/(2*len(labels)))\n",
    "    cost = tf.losses.mean_squared_error(Y, prediction_x_to_y, weights=VAR_x_to_y) + tf.losses.mean_squared_error(X, prediction_y_to_x, weights=VAR_x_to_y)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost, global_step=global_step)\n",
    "\n",
    "    init = tf.variables_initializer([W_x_to_y, W_y_to_x, b_x_to_y, b_y_to_x, global_step])\n",
    "\n",
    "linear_model_sess = tf.Session(graph=linear_graph)\n",
    "linear_model_sess.run(init)\n",
    "costs = []\n",
    "for epoch in range(EPOCH_COUNT):\n",
    "    indexes = range(1000)\n",
    "    random.shuffle(indexes)\n",
    "    for i in indexes:\n",
    "        sheep = sheep_by_size[i]\n",
    "        owl = owl_by_size[i]\n",
    "    \n",
    "    _, cost_ = linear_model_sess.run([optimizer, cost], feed_dict={X: sheep, Y: owl})\n",
    "    costs.append(cost_)\n",
    "    \n",
    "    if (epoch % 1000) == 0:\n",
    "        cost_computed = sum(costs)/len(costs)\n",
    "        costs = []\n",
    "        print(\"Epoch: %s, Cost: %s \" % (epoch, cost_computed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sheep_by_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Cost: 1.2422314882278442 \n",
      "Epoch: 0, Validation Cost: 1.2082325 \n",
      "Epoch: 5000, Training Cost: 0.6478652517855168 \n",
      "Epoch: 5000, Validation Cost: 0.36671776 \n",
      "Epoch: 10000, Training Cost: 0.24224368658661843 \n",
      "Epoch: 10000, Validation Cost: 0.14661565 \n",
      "Epoch: 15000, Training Cost: 0.10510776083022356 \n",
      "Epoch: 15000, Validation Cost: 0.067497484 \n",
      "Epoch: 20000, Training Cost: 0.056137423310428855 \n",
      "Epoch: 20000, Validation Cost: 0.042438935 \n",
      "Epoch: 25000, Training Cost: 0.034140959068760274 \n",
      "Epoch: 25000, Validation Cost: 0.027652107 \n",
      "Epoch: 30000, Training Cost: 0.022573512648418545 \n",
      "Epoch: 30000, Validation Cost: 0.018167293 \n"
     ]
    }
   ],
   "source": [
    "# Train a DNN\n",
    "STARTER_LEARNING_RATE = 0.1\n",
    "BATCH_SIZE=50\n",
    "ITERATION_COUNT = 30001\n",
    "\n",
    "TRAINING_IND = random.sample(range(1000), 800)\n",
    "non_training_ind = list(set(range(1000)) - set(TRAINING_IND))\n",
    "VALID_IND = random.sample(non_training_ind, 100)\n",
    "TEST_IND = list(set(range(1000)) - set(TRAINING_IND) - set(VALID_IND))\n",
    "\n",
    "dnn_graph = tf.Graph()\n",
    "with dnn_graph.as_default():\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(STARTER_LEARNING_RATE, global_step, 10000, 0.99, staircase=True)\n",
    "\n",
    "    # TF graph input\n",
    "    X = tf.placeholder(\"float64\", shape=(BATCH_SIZE,128))\n",
    "    Y = tf.placeholder(\"float64\", shape=(BATCH_SIZE,128))\n",
    "    with tf.device('/gpu:0'):\n",
    "\n",
    "        dense = tf.layers.dense(inputs=Y, units=512, activation=tf.nn.relu)\n",
    "        dense2 = tf.layers.dense(inputs=dense, units=256, activation=tf.nn.relu)\n",
    "        prediction_y_to_x = tf.layers.dense(inputs=dense2, units=128, activation=None)\n",
    "\n",
    "        #cost = tf.reduce_sum(tf.pow(prediction - Y, 2)/(2*len(labels)))\n",
    "        cost = tf.losses.mean_squared_error(X, prediction_y_to_x)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost, global_step=global_step)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        dnn_model_sess = tf.Session(config=tf.ConfigProto(log_device_placement=True), graph=dnn_graph)\n",
    "        dnn_model_sess.run(init)\n",
    "\n",
    "    costs = []\n",
    "    for iteration in range(ITERATION_COUNT):\n",
    "        sample_range = random.sample(TRAINING_IND, BATCH_SIZE)\n",
    "        owl_sample = [owl_by_size[i] for i in sample_range]\n",
    "        sheep_sample = [sheep_by_size[i] for i in sample_range]\n",
    "        _, cost_ = dnn_model_sess.run([optimizer, cost], feed_dict={X: owl_sample, Y: sheep_sample})\n",
    "        costs.append(cost_)\n",
    "\n",
    "        if (iteration % 5000) == 0:\n",
    "            cost_computed = sum(costs)/len(costs)\n",
    "            costs = []\n",
    "            print(\"Epoch: %s, Training Cost: %s \" % (iteration, cost_computed))\n",
    "            valid_owls = [owl_by_size[i] for i in VALID_IND][:50]\n",
    "            valid_sheep = [sheep_by_size[i] for i in VALID_IND][:50] \n",
    "            valid_cost_ = dnn_model_sess.run(cost, feed_dict = {X: owl_sample, Y: sheep_sample})\n",
    "            print(\"Epoch: %s, Validation Cost: %s \" % (iteration, valid_cost_))\n",
    "\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(dnn_model_sess, \"/tmp/model.ckpt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: The name 'save_5/Const:0' refers to a Tensor which does not exist. The operation, 'save_5/Const', does not exist in the graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-614481e6cf6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdnn_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdnn_model_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_model_sess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/tmp/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/calpeyser/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1065\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m-> 1067\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: The name 'save_5/Const:0' refers to a Tensor which does not exist. The operation, 'save_5/Const', does not exist in the graph."
     ]
    }
   ],
   "source": [
    "# Restore \n",
    "with dnn_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    dnn_model_sess = tf.Session(config=tf.ConfigProto(log_device_placement=True), graph=dnn_graph)\n",
    "    saver.restore(dnn_model_sess, \"/tmp/model.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model /home/calpeyser/sketch/models/aaron_sheep/lstm/vector.\n",
      "INFO:tensorflow:Restoring parameters from /home/calpeyser/sketch/models/aaron_sheep/lstm/vector\n",
      "Will encode\n",
      "Will predict\n",
      "INFO:tensorflow:Loading model /home/calpeyser/sketch/models/owl/lstm/vector.\n",
      "INFO:tensorflow:Restoring parameters from /home/calpeyser/sketch/models/owl/lstm/vector\n",
      "Will decode\n",
      "Will draw\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Lets do some predictions\n",
    "def svg_len(paths):\n",
    "    out = 0\n",
    "    for line in paths:\n",
    "        out += line.length()\n",
    "    return out\n",
    "\n",
    "def predict_for_indexes(indexes):\n",
    "    load_checkpoint(sess, sheep_model_dir)\n",
    "    sheeps = [sheep_train_set.strokes[i] for i in indexes]\n",
    "    print(\"Will encode\")\n",
    "    encodings = [encode(sheep_eval_model, sheep, max_len=250) for sheep in sheeps]\n",
    "    print(\"Will predict\")\n",
    "    predictions = dnn_model_sess.run(prediction_y_to_x, feed_dict = {Y: encodings})\n",
    "    load_checkpoint(sess, owl_model_dir)\n",
    "    print(\"Will decode\")\n",
    "    decodings = [decode(owl_eval_model, owl_sample_model, prediction) for prediction in predictions]\n",
    "    \n",
    "    print(\"Will draw\")\n",
    "    res = []\n",
    "    for sheep, owl in zip(sheeps, decodings):   \n",
    "        draw_strokes(sheep, svg_filename='/home/calpeyser/sketch/sketches/in.svg')\n",
    "        draw_strokes(owl, svg_filename = '/home/calpeyser/sketch/sketches/out.svg')      \n",
    "        in_paths, _ = svg2paths('/home/calpeyser/sketch/sketches/in.svg')\n",
    "        out_paths, _ = svg2paths('/home/calpeyser/sketch/sketches/out.svg')\n",
    "        in_length = svg_len(in_paths)\n",
    "        out_length = svg_len(out_paths)\n",
    "        res.append((in_length, out_length))\n",
    "    return res\n",
    "\n",
    "lens_for_sheep_transforms = predict_for_indexes(random.sample(TEST_IND, BATCH_SIZE))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lens_for_sheep_transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8dc1e9e20b5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPKL_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/calpeyser/sketch/labels/lens_for_owl_transforms'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPKL_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlens_for_sheep_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lens_for_sheep_transforms' is not defined"
     ]
    }
   ],
   "source": [
    "PKL_path = '/home/calpeyser/sketch/labels/lens_for_owl_transforms'\n",
    "f = open(PKL_path, 'wb')\n",
    "pickle.dump(lens_for_sheep_transforms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3598465412570403\n",
      "85.67053177891087\n",
      "0.5436915249756787\n"
     ]
    }
   ],
   "source": [
    "X_ = [a[0] for a in lens_for_sheep_transforms]\n",
    "Y_ = [a[1] for a in lens_for_sheep_transforms]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X_, Y_)\n",
    "print(slope)\n",
    "print(intercept)\n",
    "print(r_value ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
